---
title: "Modeling Tasks"
output: html_document
date: "2023-06-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Task 1: Set up a training set and a validation set using application_train.csv data set to do cross-validation.

```{r}
library(tidyverse)
library(e1071)
library(C50)
library(psych)
library(caret)
library(rminer)
library(rmarkdown)
library(matrixStats)
library(knitr)

setwd("~/IS-6812")
app <- read.csv(file = "application_train.csv", stringsAsFactors = TRUE)
app$TARGET <- factor(app$TARGET)
```

```{r}
set.seed(500)
folds <- createFolds(app$TARGET, k = 3)
str(folds)

# first iteration of cross validation
# prepared training and test sets 
app_test <- app[folds[[1]], ]
app_train <- app[-folds[[1]],]

str(app_test)
str(app_train)

prop.table(table(app_train$TARGET))
prop.table(table(app_test$TARGET))

# compared with the class distribution in the whole data set
prop.table(table(app$TARGET))

# model using the training set
app_nb <- naiveBayes(app_train$TARGET~.,app_train)
app_nb
```


```{r}
# second iteration of cv evaluation
# training and test data
app_test2 <- app[folds[[2]], ]
app_train2 <- app[-folds[[2]],]

prop.table(table(app_train2$TARGET))
prop.table(table(app_test2$TARGET))

# model using the training set
app_nb2 <- naiveBayes(app_train2$TARGET~.,app_train2)

```

## Task 2: Identify the performance benchmark established by the majority class classifier. 

```{r}
# performance evaluation metrics on 1st fold
predicted_TARGET <- predict(app_nb, app_train)
mmetric(app_train$TARGET, predicted_TARGET, metric="CONF") #confusion matrix
mmetric(app_train$TARGET, predicted_TARGET, metric=c("ACC","TPR","PRECISION","F1"))
```


```{r}
# performance evaluation metrics on 2nd fold
predicted_TARGET2 <- predict(app_nb2, app_train2)
mmetric(app_train2$TARGET, predicted_TARGET2, metric="CONF") #confusion matrix
mmetric(app_train2$TARGET, predicted_TARGET2, metric=c("ACC","TPR","PRECISION","F1"))
```

>With these performance benchmark metrics, you can see that accuracy is at 30.62042 for the first fold and then decreases to 25.92 on the second fold for the number of correctly predicted classes. You can see from the confusion matrices that the True Positive and False Negative are higher than the other values, because there are significantly more '0's' associated with the target variable. The F1 score is the mean of precision and sensitivity at 40.49 at the first fold and 33.577 for the second fold.
